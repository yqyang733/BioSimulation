ğŸ‘ è¿ç§»å­¦ä¹ |å†»ç»“éƒ¨åˆ†ç½‘ç»œå±‚å‚æ•°

---
[TOC]

---
ç½‘ç»œç»“æ„ç¤ºä¾‹ï¼Œä»¥ä¸‹å‚æ•°è·å¾—å‡ä»¥è¯¥ç½‘ç»œä¾‹å­ä¸ºåŸºå‡†ã€‚

```python
import torch
import torch.nn as nn

class Net(nn.Module):

    def __init__(self, num_class=10):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3),
            nn.ReLU(inplace=True),
            nn.Conv2d(in_channels=6, out_channels=9, kernel_size=3),
            nn.ReLU(inplace=True),
        )

        self.classifier = nn.Sequential(
            nn.Linear(9*8*8, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.5),
            nn.Linear(128, 64),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.2),
            nn.Linear(64, num_class)
        )

    def forward(self, x):
        output = self.features(x)
        output = output.view(output.size()[0], -1)
        output = self.classifier(output)

        return output
```

## ç½‘ç»œç»“æ„

>Net:
>
>â€¦â€¦conv:
>
>â€¦â€¦â€¦â€¦Conv2d  
>â€¦â€¦â€¦â€¦nn.ReLU  
>â€¦â€¦â€¦â€¦nn.Conv2d  
>â€¦â€¦â€¦â€¦nn.ReLU  
>
>â€¦â€¦classifier:
>
>â€¦â€¦â€¦â€¦nn.Linear  
>â€¦â€¦â€¦â€¦nn.ReLU  
>â€¦â€¦â€¦â€¦nn.Dropout  
>â€¦â€¦â€¦â€¦nn.Linear  
>â€¦â€¦â€¦â€¦nn.ReLU  
>â€¦â€¦â€¦â€¦nn.Dropout  
>â€¦â€¦â€¦â€¦nn.Linear  

## è·å–æ·±åº¦ç½‘ç»œç»“æ„æ‰€æœ‰å±‚çš„åç§°
```python
from temodel import Net

model = Net()
print(model.named_parameters())
model_named_parameters = [x[0] for x in model.named_parameters()]
print(model_named_parameters)
print(len(model_named_parameters))

# ['conv.0.weight', 'conv.0.bias', 'conv.2.weight', 'conv.2.bias', 'classifier.0.weight', 'classifier.0.bias', 'classifier.3.weight', 'classifier.3.bias', 'classifier.6.weight', 'classifier.6.bias']
# 10
```

## å†»ç»“ç‰¹å®šçš„ç½‘ç»œå±‚
```python
from temodel import Net

model = Net()
freezed = ['classifier.6.weight', 'classifier.6.bias']  # å†»ç»“çš„å‚æ•°å±‚çš„åå­—
for temp in model.named_parameters():
    if temp[0] not in freezed:
        temp[1].requires_grad = False
    print(temp)

('conv.0.weight', Parameter containing:
tensor([[[[-1.8200e-01,  1.6674e-01,  9.5946e-03],
          [ 8.4068e-02,  1.4151e-01, -1.0028e-01],
          [ 1.5293e-01, -4.7159e-03, -1.7067e-01]],

         [[ 8.3601e-02, -8.9975e-02, -2.6933e-02],
          [ 1.5043e-01, -3.7437e-02, -1.6915e-04],
          [-1.1426e-02, -1.7465e-01, -1.0773e-01]],

         [[-1.4512e-01,  1.7156e-01,  1.1475e-01],
          [ 3.6494e-02,  5.9489e-02,  1.6171e-01],
          [ 2.6965e-02,  2.4817e-02,  4.6113e-02]]],
          â€¦â€¦
           [ 5.4867e-02,  3.9649e-02, -7.3610e-02,  9.6846e-02, -6.6571e-02,
          3.1876e-02,  5.4634e-02,  1.2337e-01,  1.0418e-01, -1.1522e-01,
         -1.0200e-01, -4.7438e-03,  9.2992e-03,  7.1213e-05,  1.0981e-01,
         -8.8424e-02, -1.1785e-01, -8.0597e-02, -3.5861e-02,  1.2843e-02,
          1.7337e-02,  1.0205e-01,  3.4688e-02, -1.2413e-01, -1.2472e-01,
          5.9257e-03,  8.2976e-02, -4.0286e-02, -6.5295e-02,  3.4693e-02,
          8.2521e-02, -5.9805e-02, -3.8180e-02, -1.7155e-02, -5.8191e-02,
         -9.8856e-03,  6.0545e-02, -9.5208e-02,  1.0793e-01, -7.0142e-02,
          3.4183e-02,  8.4833e-02, -1.1027e-02, -6.5888e-02, -3.1319e-02,
          2.1325e-02, -8.6367e-02,  2.8357e-02,  6.4043e-03,  2.1796e-02,
          2.0603e-02, -3.7512e-02, -2.4294e-02,  5.3814e-02,  9.7257e-02,
         -3.2063e-02, -9.6578e-02, -3.3558e-02,  1.1749e-01,  1.1061e-01,
         -9.2184e-02, -4.8170e-03,  6.1042e-02, -1.0477e-01]],
       requires_grad=True))
('classifier.6.bias', Parameter containing:
tensor([-0.0664, -0.0846, -0.1110, -0.0077, -0.0015,  0.0633,  0.0856, -0.1081,
        -0.0138, -0.0422], requires_grad=True))
```